{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable = '/home/sirui/miniconda3/envs/myenv/bin/python'\n",
    "sys.path.insert(0, '/home/sirui/miniconda3/envs/myenv/lib/python3.8/site-packages')\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data,InMemoryDataset, download_url\n",
    "from typing import Optional, Callable, List, Union, Tuple, Dict, Iterable\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as sla\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as img\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.utils import subgraph\n",
    "from Graph_Construction import adjacency_matrix, get_dataset, MyOwnDataset\n",
    "from Augmentations import UniformSample, EdgePerturbation, NodeAttrMask, RWSample, random\n",
    "from contrasive import Contrastive\n",
    "from GraphCL import GraphCL, Encoder, GCN, GraphUnsupervised, NodeUnsupervised\n",
    "from Superpixel import return_from_sp,return_from_sp_bool, process_superpixel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "import os\n",
    "# Assuming VQVAE class and other components are already defined\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "from datetime import datetime\n",
    "project_root = \"Indian_Pines/\"   ### Please change the root!!!\n",
    "def load_data(project_root):\n",
    "    \n",
    "    mat = scipy.io.loadmat(project_root+'Indian_pines.mat')\n",
    "    IP_dataset=mat[\"indian_pines\"]/10000\n",
    "\n",
    "    mat = scipy.io.loadmat(project_root+'Indian_pines_gt.mat')\n",
    "    IP_gt=mat[\"indian_pines_gt\"]\n",
    "\n",
    "    ch_num = np.size(IP_dataset,2)\n",
    "    band_list = np.zeros(ch_num-20)\n",
    "    for i in range(0,103):\n",
    "          band_list[i]=i\n",
    "    for i in range(108,149):\n",
    "          band_list[i-5]=i\n",
    "    for i in range(163,219):\n",
    "          band_list[i-19]=i\n",
    "    band_list=np.array(band_list,dtype=int)\n",
    "    IP_dataset=IP_dataset[:,:,band_list]\n",
    "    \n",
    "    Dim=np.array([np.size(IP_dataset,0),np.size(IP_dataset,1),np.size(IP_dataset,2)])\n",
    "    bands_num = Dim[2]\n",
    "    bands_xy_num = Dim[2]+2\n",
    "\n",
    "    num_classes=np.max(IP_gt)\n",
    "\n",
    "    y_c, x_c = np.meshgrid(np.arange(Dim[0]), np.arange(Dim[1]))\n",
    "    cor=np.dstack((x_c,y_c))/144\n",
    "    IP_dataset=np.concatenate((IP_dataset, cor), axis=2)\n",
    "\n",
    "    data = np.reshape(IP_dataset,(Dim[0]*Dim[1],bands_xy_num))\n",
    "    gt_flat=np.reshape(IP_gt,(Dim[0]*Dim[1],1))\n",
    "    newDim=np.size(data,0)\n",
    "    return IP_dataset,IP_gt,Dim,bands_num,bands_xy_num,num_classes,data,gt_flat,newDim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "IP_dataset,IP_gt,Dim,bands_num,bands_xy_num,num_classes,data,gt_flat,newDim=load_data(project_root)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "colorList = [\"#000000\",\"#601d97\",\"#00d300\", \"#87ff00\",\"#2d9662\",\"#387a41\",\"#ac5c2e\",\"#ff8a54\",\"#00ffff\",\"#915085\",\"#ffffff\",\"#dec6de\",\"#ff0000\",\"#980000\",\"#0071ff\",\"#ffff00\",\"#f4a300\"]\n",
    "\n",
    "my_cmap = ListedColormap(colorList, name=\"my_cmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oa_perclass(gt, pred):\n",
    "    oa_perclass = []\n",
    "    for i in range(1, 17):\n",
    "        oa_perclass.append(accuracy_score(gt[gt == i], pred[gt == i]))\n",
    "    return oa_perclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(project_root, config):\n",
    "    num_epochs,Second_gen,n_layers,p_lr,num_labels,num_seg,sigma,WeightMode,xy_scaler,lamda=config.num_epochs,config.Second_gen,config.n_layers,config.p_lr,config.num_labels,config.num_seg,config.sigma,config.WeightMode,config.xy_scaler,config.lamda\n",
    "    IP_dataset,IP_gt,Dim,bands_num,bands_xy_num,num_classes,data,gt_flat,newDim=load_data(project_root)\n",
    "    train_m=np.load(project_root+\"train_mask_\"+str(num_labels)+\".npy\",allow_pickle=True)\n",
    "    data,gt_flat,train_m,slic_graph=process_superpixel(IP_dataset,IP_gt,train_m,num_seg,num_labels,Dim,project_root,'mean')\n",
    "    def options(mode,k,sigma,miu):\n",
    "      options = {\n",
    "                \"NeighborMode\": 'KNN',\n",
    "                \"k\": k,\n",
    "                \"WeightMode\": mode,\n",
    "                \"t\":sigma**2,\n",
    "                \"xy_scaler\":miu,\n",
    "                }\n",
    "      return options\n",
    "    options=options(WeightMode,10,sigma,xy_scaler)\n",
    "    L=adjacency_matrix(data,options)\n",
    "    data_=get_dataset(data,gt_flat,L,train_m,None,options)\n",
    "    print(data_)\n",
    "    dataset=MyOwnDataset(\"\",data_,Second_gen=Second_gen)\n",
    "    dataset.process()\n",
    "    np.shape(np.where(dataset.data.train_mask == True))\n",
    "    embed_dim = 1024\n",
    "    encoder = Encoder(feat_dim=dataset.data.x.shape[1], hidden_dim=embed_dim, \n",
    "                  n_layers=n_layers,pool='sum',node_level=False, graph_level=True)\n",
    "    GraphCL_m = GraphCL(dim=embed_dim, aug_1=config.aug1,aug_2=config.aug2, aug_ratio=config.aug_ratio, lamda=config.lamda)\n",
    "    evaluator = GraphUnsupervised(dataset,classifier=config.classifier,device=device, log_interval=1\n",
    "                              )\n",
    "    evaluator.setup_train_config(batch_size = 128, p_lr=p_lr, p_epoch=num_epochs, p_weight_decay=1e-5)\n",
    "    acc, sd ,idx,result, test_scores_m,train_scores=evaluator.evaluate(learning_model=GraphCL_m, encoder=encoder)\n",
    "    result= return_from_sp(slic_graph,result,Dim)\n",
    "    print(train_scores)\n",
    "    np.save((project_root+\"output/result/graphcl_\"+str(Second_gen)+str(n_layers)+str(num_labels)+str(num_seg)+str(sigma)+str(options[\"WeightMode\"])+str(options[\"xy_scaler\"])+str(config.lamda)+str(config.aug1)+str(config.aug2)+\"s.npy\"), result)\n",
    "    print('Best epoch %d: acc %.4f +/-(%.9f)'%((idx+1), acc, sd))\n",
    "    fig= plt.figure(figsize=(5, 4))   \n",
    "    plt.plot(test_scores_m)\n",
    "    plt.title('Best epoch %d: acc %.4f +/-(%.9f)'%((idx+1), acc, sd))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Test'], loc='upper left')\n",
    "    plt.savefig(project_root+'output/plots/plot_graphcl_'+str(Second_gen)+str(n_layers)+str(num_labels)+str(num_seg)+str(sigma)+str(options[\"WeightMode\"])+str(options[\"xy_scaler\"])+str(config.lamda)+str(config.aug1)+str(config.aug2)+'s.png')\n",
    "    plt.show()\n",
    "    print(result.max())\n",
    "    result[0]=16\n",
    "    result[1]=0\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "    ax1 = fig.add_subplot(2,2,1)\n",
    "    ax1=plt.imshow(np.reshape(result,[Dim[0],Dim[1]]),cmap=my_cmap)\n",
    "    plt.title(\"predict\")\n",
    "    plt.xlabel(\"X pixel scaling\")\n",
    "    plt.ylabel(\"Y pixels scaling\")\n",
    "    ax2 = fig.add_subplot(2,2,2)\n",
    "    o_train_m=return_from_sp_bool(slic_graph,train_m,Dim)\n",
    "    ax2=plt.imshow(np.reshape(o_train_m,[Dim[0],Dim[1]]),cmap=my_cmap)\n",
    "    plt.title(\"Trianing Image\")\n",
    "    plt.xlabel(\"X pixel scaling\")\n",
    "    plt.ylabel(\"Y pixels scaling\")\n",
    "    ax3 = fig.add_subplot(2,2,3)\n",
    "    ax3=plt.imshow(IP_gt,cmap=my_cmap)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.xlabel(\"X pixel scaling\")\n",
    "    plt.ylabel(\"Y pixels scaling\")\n",
    "    ax2 = fig.add_subplot(2,2,4)\n",
    "    maskimage=np.reshape(result,[Dim[0],Dim[1]])\n",
    "    maskimage[np.where(IP_gt==0)]=0\n",
    "    maskimage=np.reshape(np.array(maskimage),[Dim[0],Dim[1]])\n",
    "    ax2=plt.imshow(maskimage,cmap=my_cmap)\n",
    "    plt.title(\"Mask Image\")\n",
    "    plt.xlabel(\"X pixel scaling\")\n",
    "    plt.ylabel(\"Y pixels scaling\")\n",
    "    plt.savefig(project_root+'output/plots/fig_graphcl_'+str(Second_gen)+str(n_layers)+str(num_labels)+str(num_seg)+str(sigma)+str(options[\"WeightMode\"])+str(options[\"xy_scaler\"])+str(config.lamda)+str(config.aug1)+str(config.aug2)+'s.png')\n",
    "    plt.show()\n",
    "    o_train_m=np.load(project_root+\"train_mask_\"+str(num_labels)+\".npy\",allow_pickle=True)\n",
    "    tr=np.reshape(o_train_m,[Dim[0],Dim[1]])\n",
    "    gt=IP_gt\n",
    "    gt[np.where(tr==True)]=0\n",
    "    test_acc = accuracy_score(IP_gt[np.where(gt!=0)], maskimage[np.where(gt!=0)])\n",
    "    print(test_acc)\n",
    "\n",
    "    pred=maskimage[np.where(gt!=0)]\n",
    "    gt=IP_gt[np.where(gt!=0)]\n",
    "    plt.show()\n",
    "    conf_matrix=confusion_matrix(gt, pred)\n",
    "    acc_score=accuracy_score(gt, pred)\n",
    "    cohen_kappa=cohen_kappa_score(gt, pred)\n",
    "    class_report=classification_report(gt, pred)\n",
    "    oa_perclass=get_oa_perclass(gt, pred)\n",
    "    print(conf_matrix,\"OA:\",acc_score,\"Kappa:\",cohen_kappa,class_report,oa_perclass)\n",
    "\n",
    "    # Saving the results to a text file\n",
    "    outputfile = f\"\"\"\n",
    "    START!Num_epochs,Second_gen,n_layers,p_lr,num_labels,num_seg,sigma,WeightMode,xy_scaler:{ num_epochs,Second_gen,n_layers,p_lr,num_labels,num_seg,sigma,WeightMode,xy_scaler}\n",
    "    aug1,aug2,ratio,lamda,classifier:{config.aug1,config.aug2, config.aug_ratio,config.lamda,config.classifier}\n",
    "    Accuracy Score: {test_acc}\n",
    "    Confusion Matrix:\n",
    "    {conf_matrix}\n",
    "    Accuracy Score (non-zero gt): {acc_score}\n",
    "    Cohen Kappa Score: {cohen_kappa}\n",
    "    Classification Report:\n",
    "    {class_report}\n",
    "    OA Per Class:\n",
    "    {oa_perclass}\n",
    "    \"\"\"\n",
    "    return outputfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_path=project_root+'output/txt/result_'+str(current_time)+'.txt'\n",
    "\n",
    "class TrainingConfig:\n",
    "    num_epochs=400\n",
    "    Second_gen=6\n",
    "    n_layers=8\n",
    "    p_lr=0.0000000005\n",
    "    num_labels = 2000\n",
    "    num_seg=9000\n",
    "    sigma=1\n",
    "    WeightMode=\"Binary\"\n",
    "    xy_scaler=0.6\n",
    "    aug1=\"strong\"\n",
    "    aug2=\"weak\"\n",
    "    aug_ratio=0.4\n",
    "    lamda=0.83\n",
    "    classifier='LogReg'\n",
    "config = TrainingConfig()\n",
    "results=[]\n",
    "for num_labels in [10,20,30,40,50,2000]:\n",
    "    config.num_labels=num_labels\n",
    "    result=experiment(project_root, config)\n",
    "    results.append(result)\n",
    "with open(file_path, 'w') as file:\n",
    "    for i in range(0,len(results)):\n",
    "        file.write(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
